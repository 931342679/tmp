!apt install openjdk-8-jdk-headless
!wget -P /content https://archive.apache.org/dist/spark/spark-3.0.2/spark-3.0.2-bin-hadoop3.2.tgz
!tar xf spark-3.0.2-bin-hadoop3.2.tgz

!pip install -q findspark
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.0.2-bin-hadoop3.2"

!update-alternatives --config java

import findspark
findspark.init()
from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[*]").getOrCreate()

data = [{"key":"A","val":1}, {"key":"B","val":2}]
df = spark.createDataFrame(data)
df.createOrReplaceTempView("df")
df.show()

from pyspark.sql.functions import udf
from pyspark.sql.types import StringType
def my_udf(value, spark_session):
  return spark_session.sql(f"select 'add_str' as key2 from df where key = '{value}'").first()["key2"]

udf_function = udf(lambda x: my_udf(x, spark), StringType())
df = df.withColumn("result", udf_function(df["key"]))
df.show()
spark.stop()
